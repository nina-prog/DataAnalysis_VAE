{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_v1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nina-prog/DataAnalysis_VAE/blob/main/VAE_v1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srk9OHyCZDzL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcUlg_PrMiyC"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk9i4M00iwYs"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrTqGPsZceo"
      },
      "source": [
        "### Load ecg5000 data using read_csv\n",
        "ecg5000 = pd.read_csv('ECG5000_ALL.txt', sep='\\s+', header=None)\n",
        "\n",
        "### Delete label-column first (column 0)\n",
        "ecg5000.drop(ecg5000.columns[[0]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdbiFe4pZlQv"
      },
      "source": [
        "### Optional test and info about data set\n",
        "print(\"Type of ecg5000: \\t \\t {}\".format(type(ecg5000)))\n",
        "print(\"Dimensions of ecg5000: \\t \\t {}\".format(ecg5000.shape))\n",
        "print(\"Number of elements of ecg5000: \\t {}\".format((ecg5000.size)))\n",
        "print(\"Display first 10 rows of ecg5000: \\n {}\".format(ecg5000.head(10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOl-yE1aizs4"
      },
      "source": [
        "## Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCvRjcSqjFED"
      },
      "source": [
        "### Normalize dataframe with min-max-normalization to range between [-0.8, 0.8] using sklearn MinMaxScaler\n",
        "min_max_scaler = MinMaxScaler(feature_range=(-0.8,0.8))\n",
        "scaled_ecg5000 = pd.DataFrame(min_max_scaler.fit_transform(ecg5000))\n",
        "print(scaled_ecg5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Qxc-o8i2cV"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FuU0-HYavQx"
      },
      "source": [
        "### Split Data into 80/20 Training, Test\n",
        "trainDF, testDF = train_test_split(scaled_ecg5000, test_size=0.2)\n",
        "# Optional test and info about new data sets\n",
        "print(\"Shape of Training DataFrame: \\t {}\".format(trainDF.shape))\n",
        "print(\"Shape of Test DataFrame: \\t {}\".format(testDF.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqDAiFlPipdc"
      },
      "source": [
        "## Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stkCjqkHiHBo"
      },
      "source": [
        "### Convert to array\n",
        "x_train = trainDF.to_numpy()\n",
        "x_test = testDF.to_numpy()\n",
        "\n",
        "### Reshape input into [samples, timesteps, features]\n",
        "s_train = len(trainDF.index) # samples\n",
        "s_test = len(testDF.index) # samples\n",
        "n_train = len(trainDF.columns) # time steps\n",
        "n_test = len(testDF.columns) # time steps\n",
        "x_train = x_train.reshape(s_train, n_train, 1)\n",
        "x_test = x_test.reshape(s_test, n_test, 1)\n",
        "\n",
        "### Properties\n",
        "print(\"Shape of reshaped train dataset: {}\".format(x_train.shape))\n",
        "print(\"Shape of reshaped test dataset: {}\".format(x_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeXLn2bUYa7g"
      },
      "source": [
        "# Create Sample Layer\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuO7o5GGYg3y"
      },
      "source": [
        "#############################################################sample flyer function die f√ºr vae verwendet wird"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F9x-KyKM4NJ"
      },
      "source": [
        "# Build Variational Autoencoder (VAE)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmlHrviGtyZ"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_pSJx0oFlvB"
      },
      "source": [
        "### For better understanding visit: https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e\r\n",
        "### For better understanding of layers and Recreating auto encoders visit: https://machinelearningmastery.com/lstm-autoencoders/\r\n",
        "### or for code: https://gist.github.com/GerardBCN/40349b39bc45d4550141aff6966d1619#file-stock_price_autoencoding-ipynb\r\n",
        "### For Reshaping Issues: https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\r\n",
        "\r\n",
        "### fit model\r\n",
        "encoding_dim = 140\r\n",
        "epochs = 50\r\n",
        "latent_dim = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hcpCe0zGwQl"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4194a4eCBSh5"
      },
      "source": [
        "### Define Encoder Layers\r\n",
        "inputs = keras.Input(shape=(140, 1), name='Input_layer')\r\n",
        "encoded = Bidirectional(layers.LSTM(encoding_dim, activation='tanh', name='Encode_1'))(inputs)\r\n",
        "#5, because 5 class in data ecg5000 - evtl 2,1\r\n",
        "encoded = layers.Dense(5, activation='tanh', name='Encode_2')(encoded)\r\n",
        "# VAE\r\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(encoded)\r\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(encoded)\r\n",
        "z = Sampling()([z_mean, z_log_var])\r\n",
        "\r\n",
        "### Build Encoder\r\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\r\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_PrqOCOG244"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxnUeH7FBJVH"
      },
      "source": [
        "### Define Decoder Layers\r\n",
        "decoded = layers.Dense(140, activation='tanh', name='Decode_1')(encoded)\r\n",
        "decoded = layers.Reshape((140,1), name='Decode_2')(decoded)\r\n",
        "decoded = Bidirectional(layers.LSTM(encoding_dim, return_sequences=True, activation='tanh', name='Decode_3'))(decoded)\r\n",
        "outputs = TimeDistributed(Dense(1, activation='tanh', name=''),name='Output_Layer')(decoded)\r\n",
        "\r\n",
        "### Build Decoder\r\n",
        "##################################################################################decoder = keras.Model(encoded, outputs) somewhat\r\n",
        "\r\n",
        "### Build Variational Autoencoder\r\n",
        "sequence_autoencoder = keras.Model(inputs, outputs)\r\n",
        "sequence_autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xDtljwCBK3t"
      },
      "source": [
        "### Train AE\r\n",
        "##################################################################################change loss for VAE\r\n",
        "sequence_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
        "history = sequence_autoencoder.fit(x_train, x_train,\r\n",
        "                epochs=epochs,\r\n",
        "                batch_size=32,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))\r\n",
        "\r\n",
        "### Recreation\r\n",
        "decoded_ecg5000 = sequence_autoencoder.predict(x_train)\r\n",
        "plot_model(sequence_autoencoder, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ8dyTK6kNNQ"
      },
      "source": [
        "# Plot Results\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIfVmINR3lji"
      },
      "source": [
        "### Test if Input fits Dim of Output\n",
        "print(\"Shape of Input x_train: {}\".format(x_train.shape))\n",
        "print(\"Shape of Output y_train: {}\".format(decoded_ecg5000.shape))\n",
        "\n",
        "### Covert to 2D DataFrame -- (\"-1\" = selecting all data)\n",
        "new_x_train= x_train.reshape(-1,140)\n",
        "new_decoded_ecg5000 = decoded_ecg5000.reshape(-1,140)\n",
        "\n",
        "print(\"Shape of Input after reshaping: {}\".format(new_x_train.shape))\n",
        "print(\"Shape of Output after reshaping: {}\".format(new_decoded_ecg5000.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG129YUrHGyU"
      },
      "source": [
        "### Plot only one sample\r\n",
        "i = 34 # indize/sample which is going to be plotted\r\n",
        "plt.figure(linewidth = 1, figsize=(25,6))\r\n",
        "plt.title('Autoencoder Result')\r\n",
        "plt.xlabel('time steps')\r\n",
        "plt.plot(new_x_train[i], label='original ecg5000')\r\n",
        "plt.plot(new_decoded_ecg5000[i], label='decoded ecg5000')\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjUjaCtkSpW"
      },
      "source": [
        "### Plot Multiple Times\n",
        "n_rows = 3                   \n",
        "n_cols = 2\n",
        "\n",
        "# Size Properties and layout design for tighter representation\n",
        "fig, axs = plt.subplots(nrows = n_rows, ncols = n_cols, figsize=(23,20))\n",
        "fig.tight_layout(w_pad=4, h_pad = 5)\n",
        "\n",
        "# Subplotting\n",
        "i = 0\n",
        "for row in range(n_rows):\n",
        "  for col in range(n_cols):\n",
        "    axs[row, col].plot(new_x_train[i])\n",
        "    axs[row, col].plot(new_decoded_ecg5000[i])\n",
        "    axs[row, col].legend([\"Original ECG5000 Sample {}\".format(i), \"Decoded ECG5000 Sample {}\".format(i)])\n",
        "    axs[row, col].set(xlabel = \"Time Steps\", ylabel = \"Heartbet Interpolated\", title = \"Sample {}\".format(i))\n",
        "    i = i + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}