{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_v1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nina-prog/DataAnalysis_VAE/blob/main/VAE_v2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srk9OHyCZDzL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hak-yuBzG9Ad"
      },
      "source": [
        "To-Do\r\n",
        "\r\n",
        "\r\n",
        "*   Layer von z_mean und z_log_var entsprechende Aktivierungsfunktionen\r\n",
        "*   nach encoder.summary (), encoder.compile(optimizer= …., loss=…) zu machen. (Das selber mit dem Decoder). Dann kann man nach trainieren des Modells : encoder.predict(DATAFRAME) machen und enthält damit die z-Werte für die Input Daten. Sonst gibt es in Tensorflow noch die Möglichkeit Layer direkt zu tracken\r\n",
        "*    plottet man nämlich den Trainings Loss gegen den Validation Loss. Ihr habt keinen validation loss (hab gerade in den code geschaut), dann könnt ihr vae.evaluate(x_test) machen und den loss von .fit gegen den loss von .evaluate plotten. (Das gleiche könnt ihr dann natürlich auch für den reconstruction loss und die kl_divergence machen, müsst ihr aber nicht. Fürs erste ist der vollständige loss.)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcUlg_PrMiyC"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk9i4M00iwYs"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrTqGPsZceo"
      },
      "source": [
        "### Load ecg5000 data using read_csv\n",
        "ecg5000 = pd.read_csv('ECG5000_ALL.txt', sep='\\s+', header=None)\n",
        "\n",
        "### Delete label-column first (column 0)\n",
        "ecg5000.drop(ecg5000.columns[[0]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdbiFe4pZlQv"
      },
      "source": [
        "### Optional test and info about data set\n",
        "print(\"Type of ecg5000: \\t \\t {}\".format(type(ecg5000)))\n",
        "print(\"Dimensions of ecg5000: \\t \\t {}\".format(ecg5000.shape))\n",
        "print(\"Number of elements of ecg5000: \\t {}\".format((ecg5000.size)))\n",
        "print(\"Display first 10 rows of ecg5000: \\n {}\".format(ecg5000.head(10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOl-yE1aizs4"
      },
      "source": [
        "## Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCvRjcSqjFED"
      },
      "source": [
        "### Normalize dataframe with min-max-normalization to range between [-0.8, 0.8] using sklearn MinMaxScaler\n",
        "min_max_scaler = MinMaxScaler(feature_range=(-0.8,0.8))\n",
        "scaled_ecg5000 = pd.DataFrame(min_max_scaler.fit_transform(ecg5000))\n",
        "print(scaled_ecg5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Qxc-o8i2cV"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FuU0-HYavQx"
      },
      "source": [
        "### Split Data into 80/20 Training, Test\n",
        "trainDF, testDF = train_test_split(scaled_ecg5000, test_size=0.2)\n",
        "# Optional test and info about new data sets\n",
        "print(\"Shape of Training DataFrame: \\t {}\".format(trainDF.shape))\n",
        "print(\"Shape of Test DataFrame: \\t {}\".format(testDF.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqDAiFlPipdc"
      },
      "source": [
        "## Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stkCjqkHiHBo"
      },
      "source": [
        "### Convert to array\n",
        "x_train = trainDF.to_numpy()\n",
        "x_test = testDF.to_numpy()\n",
        "\n",
        "### Reshape input into [samples, timesteps, features]\n",
        "s_train = len(trainDF.index) # samples\n",
        "s_test = len(testDF.index) # samples\n",
        "n_train = len(trainDF.columns) # time steps\n",
        "n_test = len(testDF.columns) # time steps\n",
        "x_train = x_train.reshape(s_train, n_train, 1)\n",
        "x_test = x_test.reshape(s_test, n_test, 1)\n",
        "\n",
        "### Properties\n",
        "print(\"Shape of reshaped train dataset: {}\".format(x_train.shape))\n",
        "print(\"Shape of reshaped test dataset: {}\".format(x_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeXLn2bUYa7g"
      },
      "source": [
        "# Create Sample Layer\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuO7o5GGYg3y"
      },
      "source": [
        "class Sampling(layers.Layer):\r\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z\"\"\"\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        z_mean, z_log_var = inputs\r\n",
        "        batch = tf.shape(z_mean)[0]\r\n",
        "        dim = tf.shape(z_mean)[1]\r\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\r\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F9x-KyKM4NJ"
      },
      "source": [
        "# Build Variational Autoencoder (VAE)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmlHrviGtyZ"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_pSJx0oFlvB"
      },
      "source": [
        "### For better understanding visit: https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e\r\n",
        "### For better understanding of layers and Recreating auto encoders visit: https://machinelearningmastery.com/lstm-autoencoders/\r\n",
        "### or for code: https://gist.github.com/GerardBCN/40349b39bc45d4550141aff6966d1619#file-stock_price_autoencoding-ipynb\r\n",
        "### For Reshaping Issues: https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\r\n",
        "\r\n",
        "### fit model\r\n",
        "encoding_dim = 140\r\n",
        "latent_dim = 2\r\n",
        "epochs = 50\r\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hcpCe0zGwQl"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4194a4eCBSh5"
      },
      "source": [
        "### Define Encoder Layers\r\n",
        "encoder_inputs = keras.Input(shape=(140, 1), name='Encoder_Input_layer')\r\n",
        "\r\n",
        "encoded = Bidirectional(layers.LSTM(encoding_dim, activation='tanh', name=''), name='Encode_1')(encoder_inputs)\r\n",
        "encoded = layers.Dense(5, activation='tanh', name='Encode_2')(encoded) #5, because 5 class in data ecg5000 - evtl 2,1\r\n",
        "z_mean = layers.Dense(latent_dim, activation=\"sigmoid\" name=\"z_mean\")(encoded) \r\n",
        "z_log_var = layers.Dense(latent_dim, activation=\"sigmoid\" name=\"z_log_var\")(encoded)\r\n",
        "\r\n",
        "z = Sampling(name='Sample_layer')([z_mean, z_log_var])\r\n",
        "\r\n",
        "### Build Encoder\r\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\r\n",
        "\r\n",
        "encoder.summary()\r\n",
        "# configure encoder for training\r\n",
        "encoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
        "\r\n",
        "plot_model(encoder, show_shapes=True, to_file='reconstruct_lstm_encoder.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_PrqOCOG244"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxnUeH7FBJVH"
      },
      "source": [
        "### Define Decoder Layers\r\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='Decoder_Input_layer')\r\n",
        "\r\n",
        "decoded = layers.Dense(140, activation='tanh', name='Decode_1')(latent_inputs)\r\n",
        "decoded = layers.Reshape((140,1), name='Decode_2')(decoded)\r\n",
        "decoded = Bidirectional(layers.LSTM(encoding_dim, return_sequences=True, activation='tanh', name=''), name='Decode_3')(decoded)\r\n",
        "\r\n",
        "decoder_outputs = TimeDistributed(Dense(1, activation='tanh', name=''),name='Decoder_Output_Layer')(decoded)\r\n",
        "\r\n",
        "### Build Decoder\r\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\r\n",
        "\r\n",
        "decoder.summary()\r\n",
        "# configure decoder for training\r\n",
        "decoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
        "\r\n",
        "plot_model(decoder, show_shapes=True, to_file='reconstruct_lstm_decoder.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAKUqMR8oSm6"
      },
      "source": [
        "## Connecting the Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR-wmYsdQXII"
      },
      "source": [
        "### For better understanding visit https://becominghuman.ai/using-variational-autoencoder-vae-to-generate-new-images-14328877e88d\r\n",
        "\r\n",
        "### Instantiate VAE model\r\n",
        "# The output of vae model is the output of decoder in which its input is taken from the output of encoder !\r\n",
        "decoder_outputs = decoder(encoder(encoder_inputs))\r\n",
        "vae = keras.Model(encoder_inputs, decoder_outputs, name='vae_v2_0')\r\n",
        "\r\n",
        "vae.summary()\r\n",
        "plot_model(vae, show_shapes=True, to_file='reconstruct_lstm_variational_autoencoder.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OlCIRCOUF-"
      },
      "source": [
        "# Train VAE\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1m0bKlZlIuL"
      },
      "source": [
        "## Define Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9hxGlDYBBKV"
      },
      "source": [
        "class VAE(keras.Model):\r\n",
        "    def __init__(self, encoder, decoder, **kwargs):\r\n",
        "        super(VAE, self).__init__(**kwargs)\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "    def train_step(self, data):\r\n",
        "        if isinstance(data, tuple):\r\n",
        "            data = data[0]\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            z_mean, z_log_var, z = encoder(data)\r\n",
        "            reconstruction = decoder(z)\r\n",
        "            # reconstruction_loss = distance between Input and Output\r\n",
        "            reconstruction_loss = tf.reduce_mean(\r\n",
        "                keras.losses.binary_crossentropy(data, reconstruction)\r\n",
        "            )\r\n",
        "            reconstruction_loss *= 28 * 28\r\n",
        "            # kl_loss = distance between distributions and thus ensures the regular laten space\r\n",
        "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\r\n",
        "            kl_loss = tf.reduce_mean(kl_loss)\r\n",
        "            kl_loss *= -0.5\r\n",
        "            total_loss = reconstruction_loss + kl_loss\r\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\r\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\r\n",
        "        return {\r\n",
        "            \"loss\": total_loss,\r\n",
        "            \"reconstruction_loss\": reconstruction_loss,\r\n",
        "            \"kl_loss\": kl_loss,\r\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfnzjwIxlShE"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkdJdc_N5SN"
      },
      "source": [
        "### To improve training see here: https://becominghuman.ai/using-variational-autoencoder-vae-to-generate-new-images-14328877e88d\r\n",
        " \r\n",
        "### Train\r\n",
        "vae = VAE(encoder, decoder, name=\"VAE\")\r\n",
        "vae.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
        "history = vae.fit(x_train, epochs=epochs, batch_size=batch_size)\r\n",
        "\r\n",
        "### Recreation\r\n",
        "bottleneck = encoder.predict(x_train) # z values\r\n",
        "decoded_ecg5000 = decoder.predict(bottleneck)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53ufa2OwJIVe"
      },
      "source": [
        "### Display the training progress\r\n",
        "# Loss vs Reconstruction_loss\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['reconstruction_loss'])\r\n",
        "plt.legend([\"Loss\", \"Reconstruction Loss\"])\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.title(\"Loss vs. Reconstruction Loss\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIrsjRDYOiI"
      },
      "source": [
        "# Train loss vs val loss\r\n",
        "# Returns the loss value & metrics values for the model in test mode\r\n",
        "val_loss = vae.evaluate(x_test)\r\n",
        "\r\n",
        "plt.figure(figsize=(20,12))\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(val_loss['val_loss'])\r\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.title(\"Loss vs. Validation Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOXeC5qZgBai"
      },
      "source": [
        "##################################################################################### TODO: Display latent space\r\n",
        "### Encode data into latent space and show the distribution using simple scatter plot\r\n",
        "bottleneck = encoder.predict(x_train)\r\n",
        "\r\n",
        "print(bottleneck)\r\n",
        "print(type(bottleneck))\r\n",
        "print(len(bottleneck))\r\n",
        "\r\n",
        "array0 = bottleneck[0]\r\n",
        "print(len(array0))\r\n",
        "print(array0.shape)\r\n",
        "array1 = bottleneck[1]\r\n",
        "print(len(array1))\r\n",
        "print(array1.shape)\r\n",
        "array2 = bottleneck[2]\r\n",
        "print(len(array2))\r\n",
        "print(array2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSBgUNCkM05C"
      },
      "source": [
        "# *i unpacks i into a tuple (i[0], i[1]), which is interpreted as (x,y) by plt.scatter\r\n",
        "# for a in bottleneck:\r\n",
        "#  for i in a:\r\n",
        "#   plt.scatter(*i)\r\n",
        "\r\n",
        "#x = array1[:,0]\r\n",
        "#y = array1[:,1]\r\n",
        "\r\n",
        "plt.figure(figsize=(18,12))\r\n",
        "plt.scatter(array0[:,0], array0[:,1], s=2)\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ8dyTK6kNNQ"
      },
      "source": [
        "# Plot Results\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIfVmINR3lji"
      },
      "source": [
        "### Test if Input fits Dim of Output\n",
        "print(\"Shape of Input x_train: {}\".format(x_train.shape))\n",
        "print(\"Shape of Output y_train: {}\".format(decoded_ecg5000.shape))\n",
        "\n",
        "### Covert to 2D Array -- (\"-1\" = make a dimension (here rows) the size that will use the remaining unspecified elements)\n",
        "new_x_train= x_train.reshape(-1,140)\n",
        "new_decoded_ecg5000 = decoded_ecg5000.reshape(-1,140)\n",
        "\n",
        "print(\"Shape of Input after reshaping: {}\".format(new_x_train.shape))\n",
        "print(\"Shape of Output after reshaping: {}\".format(new_decoded_ecg5000.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG129YUrHGyU"
      },
      "source": [
        "### Plot only one sample\r\n",
        "i = 34 # indize/sample which is going to be plotted\r\n",
        "plt.figure(linewidth = 1, figsize=(25,6))\r\n",
        "plt.title('Autoencoder Result')\r\n",
        "plt.xlabel('time steps')\r\n",
        "plt.plot(new_x_train[i], label='original ecg5000')\r\n",
        "plt.plot(new_decoded_ecg5000[i], label='decoded ecg5000')\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjUjaCtkSpW"
      },
      "source": [
        "### Plot Multiple Samples\n",
        "n_rows = 2                   \n",
        "n_cols = 2\n",
        "\n",
        "# Size Properties and layout design for tighter representation\n",
        "fig, axs = plt.subplots(nrows = n_rows, ncols = n_cols, figsize=(23,20))\n",
        "fig.tight_layout(w_pad=4, h_pad = 5)\n",
        "\n",
        "# Subplotting\n",
        "i = 5\n",
        "for row in range(n_rows):\n",
        "  for col in range(n_cols):\n",
        "    axs[row, col].plot(new_x_train[i])\n",
        "    axs[row, col].plot(new_decoded_ecg5000[i])\n",
        "    axs[row, col].legend([\"Original ECG5000 Sample {}\".format(i), \"Decoded ECG5000 Sample {}\".format(i)])\n",
        "    axs[row, col].set(xlabel = \"Time Steps\", ylabel = \"Heartbeat Interpolated\", title = \"Sample {}\".format(i))\n",
        "    i = i + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}